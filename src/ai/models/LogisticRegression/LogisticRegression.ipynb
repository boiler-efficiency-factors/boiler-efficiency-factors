{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6624a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Matplotlib font set to: Malgun Gothic\n"
     ]
    }
   ],
   "source": [
    "#효율 상위 30%를 고효율 상태로 정의.\n",
    "FILE_PATTERN = './*.csv'\n",
    "EFF_COL = '열 손실법 효율'\n",
    "TOP_PERCENT = 30\n",
    "Q_FOR_POSITIVE = 100 - TOP_PERCENT\n",
    "\n",
    "#모델 훈련 가속을 위한 설정\n",
    "FAST_SUBSAMPLE_FRAC = 0.35\n",
    "FAST_SEED = 42\n",
    "USE_RANDOM_SEARCH = True\n",
    "RANDOM_SEARCH_ITER = 12\n",
    "CV_SPLITS = 3\n",
    "SKIP_PERM_IMPORTANCE = True\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "HEAVY_MISSING_THRESHOLD = 0.80\n",
    "MAX_ITER = 2000\n",
    "\n",
    "#의미 없는 컬럼값 미리 제거\n",
    "EXCLUDE_COLUMNS = [\n",
    "    '생성일','급수펌프','배기 재 순환 온도','운전시간','확률 업데이트',\n",
    "    '효율(순간)','효율(입출력법-스팀)','정상 운전','송풍기 고장 확률',\n",
    "    'AIR 댐퍼 고장 확률','GAS 앰퍼 고장 확률','확률 업데이트 시간', '입출력법 효율'\n",
    "]\n",
    "\n",
    "import os, glob, warnings, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    font_name = 'Malgun Gothic'\n",
    "elif platform.system() == 'Darwin':\n",
    "    font_name = 'AppleGothic'\n",
    "else:\n",
    "    font_name = 'NanumGothic'\n",
    "rc('font', family=font_name)\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "print(\"[INFO] Matplotlib font set to:\", font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e48360",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No CSV files found for pattern: ./*.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(FILE_PATTERN))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo CSV files found for pattern: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFILE_PATTERN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m dfs, failed \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No CSV files found for pattern: ./*.csv"
     ]
    }
   ],
   "source": [
    "import utils.preprocessor\n",
    "import utils.data_load\n",
    "\n",
    "startData = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 전처리 + 추가 작업\n",
    "df = df_raw.copy()\n",
    "df.columns = [str(c).strip() for c in df.columns]\n",
    "df = df.replace({'-': np.nan, '–': np.nan, '—': np.nan, '': np.nan, ' ': np.nan})\n",
    "\n",
    "def to_numeric_safe(s):\n",
    "    return pd.to_numeric(s.astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
    "\n",
    "df_num = df.copy()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        try:\n",
    "            df_num[col] = to_numeric_safe(df[col])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if EFF_COL not in df_num.columns or df_num[EFF_COL].dropna().shape[0] == 0:\n",
    "    raise KeyError(f\"'{EFF_COL}' 컬럼을 찾지 못했거나 값이 없습니다.\")\n",
    "eff_series = df_num[EFF_COL].astype(float)\n",
    "thr = np.nanpercentile(eff_series, Q_FOR_POSITIVE)\n",
    "df_num['target'] = (eff_series >= thr).astype('Int64')\n",
    "print(f\"Target rule: Top {TOP_PERCENT}% (>= {thr:.4f})\")\n",
    "\n",
    "drop_cols = ['__source_file__', EFF_COL] + [c for c in EXCLUDE_COLUMNS if c in df_num.columns]\n",
    "X = df_num.drop(columns=drop_cols + ['target'], errors='ignore')\n",
    "y = df_num['target']\n",
    "\n",
    "numeric_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
    "X = X[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "null_rate = X.isna().mean()\n",
    "all_nan_cols = null_rate[null_rate == 1.0].index.tolist()\n",
    "heavy_missing_cols = null_rate[null_rate >= HEAVY_MISSING_THRESHOLD].index.tolist()\n",
    "to_drop = list(set(all_nan_cols + heavy_missing_cols))\n",
    "if to_drop:\n",
    "    print(\"Drop columns:\", to_drop[:10], \"...\" if len(to_drop) > 10 else \"\")\n",
    "    X = X.drop(columns=to_drop)\n",
    "\n",
    "valid = y.notna()\n",
    "X, y = X.loc[valid].reset_index(drop=True), y.loc[valid].astype(int).reset_index(drop=True)\n",
    "\n",
    "if FAST_SUBSAMPLE_FRAC and 0 < FAST_SUBSAMPLE_FRAC < 1.0:\n",
    "    idx = X.sample(frac=FAST_SUBSAMPLE_FRAC, random_state=FAST_SEED).index\n",
    "    X, y = X.loc[idx].reset_index(drop=True), y.loc[idx].reset_index(drop=True)\n",
    "    print(f\"[FAST] Subsampled to {len(X)} rows\")\n",
    "\n",
    "print('Final X shape:', X.shape, '/ y shape:', y.shape)\n",
    "\n",
    "counts = y.value_counts()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(['0(저효율)','1(고효율)'], [counts.get(0,0), counts.get(1,0)])\n",
    "plt.title('타깃 분포 (상위 30% = 1)')\n",
    "plt.ylabel('샘플 수')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb75621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"logit\", LogisticRegression(max_iter=MAX_ITER, solver='lbfgs'))\n",
    "])\n",
    "\n",
    "if USE_RANDOM_SEARCH:\n",
    "    param_dist = {\n",
    "        \"logit__penalty\": ['l2'],\n",
    "        \"logit__C\": np.logspace(-2, 1, 20),\n",
    "        \"logit__class_weight\": [None, \"balanced\"],\n",
    "        \"logit__solver\": ['lbfgs', 'saga'],\n",
    "        \"logit__max_iter\": [MAX_ITER],\n",
    "        \"logit__random_state\": [RANDOM_STATE],\n",
    "        \"logit__tol\": [1e-4, 5e-4, 1e-3],\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=RANDOM_SEARCH_ITER,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        refit=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best_pipe = search.best_estimator_\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "else:\n",
    "    best_pipe = pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "y_proba = best_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Test Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"=== Test Confusion Matrix ===\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "#시각화\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc:.3f}')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PR\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(rec, prec, label=f'AP={ap:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix heatmap\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = [0,1]\n",
    "plt.xticks(tick_marks, ['Pred 0','Pred 1'])\n",
    "plt.yticks(tick_marks, ['True 0','True 1'])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 기여도: 표준화 계수 Top 20 (빠름) ===\n",
    "logit = best_pipe.named_steps[\"logit\"]\n",
    "coef_series = pd.Series(logit.coef_[0], index=X.columns, name=\"coef (scaled space)\")\n",
    "coef_abs = coef_series.abs().sort_values(ascending=False)\n",
    "\n",
    "top_k = min(20, len(coef_series))\n",
    "plt.figure(figsize=(8,6))\n",
    "coef_series.loc[coef_abs.head(top_k).index].plot(kind=\"barh\")\n",
    "plt.title(\"Top Feature Coefficients (Logistic Regression, scaler : robust)\")\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
