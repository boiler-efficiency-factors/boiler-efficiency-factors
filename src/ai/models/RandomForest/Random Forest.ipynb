{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dyr5S20Y2QR"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor # RandomForestRegressor ëª¨ë¸ (Random Forest Regressor model)\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV # ë°ì´í„° ë¶„í•  ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245536,
     "status": "ok",
     "timestamp": 1762258215947,
     "user": {
      "displayName": "ì¢…í”„8ì¡°",
      "userId": "07299683942730353238"
     },
     "user_tz": -540
    },
    "id": "fpxiq-tcPy9I",
    "outputId": "2a227c2f-7e22-4865-f287-afd6e7a3001a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data_load ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ (data_load module imported successfully)\n",
      "ğŸ” ['2025-01-01'ë¶€í„° '2025-09-14'ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ë¡œë“œ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/utils/data_load.py:48: DtypeWarning: Columns (19,20,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(\n",
      "/content/drive/MyDrive/utils/data_load.py:66: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(dfs_to_concat, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì´ 257ê°œ íŒŒì¼, 8474140ê°œ í–‰ì˜ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ í•©ì³¤ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ëª¨ë“ˆ ì„í¬íŠ¸ ë° ì‹¤í–‰ (Import and run data load module)\n",
    "try:\n",
    "    import data_load\n",
    "    print(\"âœ… data_load ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ (data_load module imported successfully)\")\n",
    "    # ë°ì´í„° ë¡œë“œ (Load data - start/end dates are examples, modify as needed)\n",
    "    combined_df = data_load.load_data(start_date='2025-01-01', end_date='2025-09-14')\n",
    "    if combined_df is None or combined_df.empty:\n",
    "        print(\"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤. (Data load failed or DataFrame is empty. Stopping script.)\")\n",
    "        # exit()\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ data_load ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error importing data_load module): {e}\")\n",
    "    print(f\"'{utils_path}' ê²½ë¡œì— data_load.py íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (Check if data_load.py exists in '{utils_path}'.)\")\n",
    "    combined_df = None # ì˜¤ë¥˜ ì‹œ Noneìœ¼ë¡œ ì´ˆê¸°í™” (Initialize to None on error)\n",
    "    # exit()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Unexpected error during data load): {e}\")\n",
    "    combined_df = None\n",
    "    # exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69337,
     "status": "ok",
     "timestamp": 1762258285288,
     "user": {
      "displayName": "ì¢…í”„8ì¡°",
      "userId": "07299683942730353238"
     },
     "user_tz": -540
    },
    "id": "XHB6VCbXQW-T",
    "outputId": "511be8f5-326c-494e-8549-7717b5f2db6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… preprocessor ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ (preprocessor module imported successfully)\n",
      "\n",
      "--- ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ (Starting data preprocessing) ---\n",
      "â„¹ï¸ ë‹¤ìŒ object ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (Converting the following object columns to string): ['ìƒì„±ì¼', 'ê¸‰ìˆ˜íŒí”„ ì…ë ¥', 'ë°°ê¸°ê°€ìŠ¤ì˜¨ë„2', 'ë°°ê¸°ê°€ìŠ¤ì˜¨ë„3', 'ë°°ê¸° ì¬ ìˆœí™˜ ì˜¨ë„', 'ì—ì½” ì˜¨ë„1', 'ì—ì½” ì˜¨ë„2', 'ë²„ë„ˆì˜¨ë„', 'ì¬ìˆœí™˜ O2', 'ì¬ìˆœí™˜ NOx', 'ìš´ì „ì‹œê°„', 'í™•ë¥  ì—…ë°ì´íŠ¸ ì‹œê°„']\n",
      "âœ… Object íƒ€ì… ì»¬ëŸ¼ ë¬¸ìì—´ ë³€í™˜ ì™„ë£Œ (Object type column conversion to string complete - some may be skipped on error)\n",
      "preprocessor.preprocessor í•¨ìˆ˜ ì‹¤í–‰ ì¤‘...\n",
      "--- ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ---\n",
      "âœ… 1. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ 14ê°œ ì œê±° ì™„ë£Œ\n",
      "âœ… 1. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ\n",
      "âœ… 2. 'íš¨ìœ¨(ìˆœê°„)' ì»¬ëŸ¼ ê°’ 100 ë¯¸ë§Œìœ¼ë¡œ í•„í„°ë§ ì™„ë£Œ\n",
      "âœ… 3-1. ë²”ì£¼í˜• ë°ì´í„° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\n",
      "âœ… 3-2. ë²”ì£¼í˜• ë³€ìˆ˜ ë³€í™˜ ì™„ë£Œ\n",
      "â„¹ï¸ 3-3. ì²˜ë¦¬í•  ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "âœ… 4. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\n",
      "--- ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ ---\n",
      "âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰ ì™„ë£Œ. í˜•ìƒ: (4796529, 33) (Preprocessing function execution complete. Shape: (4796529, 33))\n",
      "âœ… 'íš¨ìœ¨(ìˆœê°„)' 100 ì´ìƒì¸ í–‰ 0ê°œ ì œê±° ì™„ë£Œ (Removed 0 rows where 'íš¨ìœ¨(ìˆœê°„)' >= 100)\n",
      "ìµœì¢… ì „ì²˜ë¦¬ ë°ì´í„° í˜•ìƒ: (4796529, 33) (Final preprocessed data shape: (4796529, 33))\n",
      "--- ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (Data preprocessing complete) ---\n"
     ]
    }
   ],
   "source": [
    "# ## ë°ì´í„° ì „ì²˜ë¦¬ (Data Preprocessing)\n",
    "\n",
    "# preprocessor.py ëª¨ë“ˆì„ ì„í¬íŠ¸í•˜ê³ , ë¡œë“œëœ ë°ì´í„°ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
    "# Import the preprocessor.py module and apply the preprocessing function to the loaded data.\n",
    "preprocessor = None # preprocessor ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "expected_preprocessor_path = os.path.join(utils_path, 'preprocessor.py') # ì˜ˆìƒ ê²½ë¡œ ë¯¸ë¦¬ ì •ì˜\n",
    "try:\n",
    "    import preprocessor\n",
    "    print(\"âœ… preprocessor ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ (preprocessor module imported successfully)\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ preprocessor ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error importing preprocessor module): {e}\")\n",
    "    print(f\"'{utils_path}' ê²½ë¡œì— preprocessor.py íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (Check if preprocessor.py exists in '{utils_path}'.)\")\n",
    "    preprocessor = None # ì˜¤ë¥˜ ì‹œ Noneìœ¼ë¡œ ì´ˆê¸°í™” (Initialize to None on error)\n",
    "    # exit()\n",
    "\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰ (Run data preprocessing)\n",
    "preprocessed_df = None # ì „ì²˜ë¦¬ í›„ ë°ì´í„°í”„ë ˆì„ ë³€ìˆ˜ ì´ˆê¸°í™” (Initialize preprocessed DataFrame variable)\n",
    "if 'combined_df' in locals() and combined_df is not None and 'preprocessor' in locals() and preprocessor is not None:\n",
    "    print(\"\\n--- ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ (Starting data preprocessing) ---\")\n",
    "\n",
    "    # Object íƒ€ì… ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (Convert object type columns to string)\n",
    "    # This step is crucial if the preprocessor uses tools like LabelEncoder that expect uniform data types.\n",
    "    object_cols = combined_df.select_dtypes(include=['object']).columns\n",
    "    if not object_cols.empty:\n",
    "        print(f\"â„¹ï¸ ë‹¤ìŒ object ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (Converting the following object columns to string): {list(object_cols)}\")\n",
    "        for col in object_cols:\n",
    "            try:\n",
    "                # Missing values might cause issues during conversion; consider filling them first if necessary.\n",
    "                # Example: combined_df[col].fillna('Unknown', inplace=True)\n",
    "                combined_df[col] = combined_df[col].astype(str)\n",
    "            except Exception as e:\n",
    "                 print(f\"âš ï¸ ì»¬ëŸ¼ '{col}' ë³€í™˜ ì¤‘ ì˜¤ë¥˜ (Error converting column '{col}'): {e}. í•´ë‹¹ ì»¬ëŸ¼ ì²˜ë¦¬ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (May skip processing this column.)\")\n",
    "        print(\"âœ… Object íƒ€ì… ì»¬ëŸ¼ ë¬¸ìì—´ ë³€í™˜ ì™„ë£Œ (Object type column conversion to string complete - some may be skipped on error)\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ ë¬¸ìì—´ë¡œ ë³€í™˜í•  Object íƒ€ì… ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (No object type columns to convert to string.)\")\n",
    "\n",
    "    # ì „ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ (Call preprocessing function)\n",
    "    try:\n",
    "        # Using copy() is recommended to preserve the original combined_df.\n",
    "        print(\"preprocessor.preprocessor í•¨ìˆ˜ ì‹¤í–‰ ì¤‘...\")\n",
    "        preprocessed_df = preprocessor.preprocessor(combined_df.copy())\n",
    "        print(f\"âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰ ì™„ë£Œ. í˜•ìƒ: {preprocessed_df.shape} (Preprocessing function execution complete. Shape: {preprocessed_df.shape})\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error executing preprocessing function): {e}\")\n",
    "        # exit() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¤‘ë‹¨ (Exit on error)\n",
    "\n",
    "    # 'íš¨ìœ¨(ìˆœê°„)' ê°’ì´ 100 ì´ìƒì¸ ë¹„ì •ìƒ ë°ì´í„° ì œê±° (Remove outliers where 'íš¨ìœ¨(ìˆœê°„)' >= 100)\n",
    "    if preprocessed_df is not None:\n",
    "        try:\n",
    "            target_col = 'íš¨ìœ¨(ìˆœê°„)' # ëª©í‘œ ë³€ìˆ˜ ì»¬ëŸ¼ëª… (Target variable column name)\n",
    "            if target_col in preprocessed_df.columns:\n",
    "                initial_rows = len(preprocessed_df)\n",
    "                # Filter out rows where the target value is abnormally high (>= 100)\n",
    "                preprocessed_df = preprocessed_df[preprocessed_df[target_col] < 100].copy()\n",
    "                removed_rows = initial_rows - len(preprocessed_df)\n",
    "                print(f\"âœ… '{target_col}' 100 ì´ìƒì¸ í–‰ {removed_rows}ê°œ ì œê±° ì™„ë£Œ (Removed {removed_rows} rows where '{target_col}' >= 100)\")\n",
    "                print(f\"ìµœì¢… ì „ì²˜ë¦¬ ë°ì´í„° í˜•ìƒ: {preprocessed_df.shape} (Final preprocessed data shape: {preprocessed_df.shape})\")\n",
    "                print(\"--- ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (Data preprocessing complete) ---\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ '{target_col}' 100 ì´ìƒ í–‰ ì œê±° ì¤‘ ì˜¤ë¥˜ (Error removing rows where '{target_col}' >= 100): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3077,
     "status": "ok",
     "timestamp": 1762258288367,
     "user": {
      "displayName": "ì¢…í”„8ì¡°",
      "userId": "07299683942730353238"
     },
     "user_tz": -540
    },
    "id": "etGFhDf1YoCY",
    "outputId": "51797291-ec76-4e6b-d0fa-d8410e8332b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë°ì´í„° í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ (Data split into train/test complete) (80%/20%)\n",
      "í•™ìŠµ ë°ì´í„° X í˜•ìƒ (Train X shape): (3837223, 32), í…ŒìŠ¤íŠ¸ ë°ì´í„° X í˜•ìƒ (Test X shape): (959306, 32)\n",
      "í•™ìŠµ ë°ì´í„° y í˜•ìƒ (Train y shape): (3837223,), í…ŒìŠ¤íŠ¸ ë°ì´í„° y í˜•ìƒ (Test y shape): (959306,)\n"
     ]
    }
   ],
   "source": [
    "# ## ë°ì´í„° ë¶„í•  (Data Splitting)\n",
    "\n",
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ í•™ìŠµìš©(Train)ê³¼ í…ŒìŠ¤íŠ¸ìš©(Test)ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤ (ë³´í†µ 80:20 ë¹„ìœ¨).\n",
    "# Split the preprocessed data into training and testing sets (typically 80:20 ratio).\n",
    "X_train, X_test, y_train, y_test = None, None, None, None # Initialize variables to None\n",
    "# Proceed only if preprocessing was successful\n",
    "if 'preprocessed_df' in locals() and preprocessed_df is not None and not preprocessed_df.empty:\n",
    "    try:\n",
    "        y_col = 'íš¨ìœ¨(ìˆœê°„)' # Define the name of the dependent variable (target) column\n",
    "        # Ensure the target column exists before attempting to drop/select it\n",
    "        if y_col not in preprocessed_df.columns:\n",
    "            raise KeyError(f\"'{y_col}' ì»¬ëŸ¼ì´ ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì— ì—†ìŠµë‹ˆë‹¤. (Column '{y_col}' not found in preprocessed DataFrame.)\")\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = preprocessed_df.drop(columns=[y_col]) # Independent variables (Features)\n",
    "        y = preprocessed_df[y_col]               # Dependent variable (Target)\n",
    "\n",
    "        # Split data into training and test sets using train_test_split\n",
    "        # test_size=0.2 means 20% for testing, 80% for training\n",
    "        # random_state ensures the split is the same every time the code runs (for reproducibility)\n",
    "        # shuffle=True (default) shuffles data before splitting\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "        # Print shapes of the resulting datasets to confirm the split\n",
    "        print(\"\\nâœ… ë°ì´í„° í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ (Data split into train/test complete) (80%/20%)\")\n",
    "        print(f\"í•™ìŠµ ë°ì´í„° X í˜•ìƒ (Train X shape): {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„° X í˜•ìƒ (Test X shape): {X_test.shape}\")\n",
    "        print(f\"í•™ìŠµ ë°ì´í„° y í˜•ìƒ (Train y shape): {y_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„° y í˜•ìƒ (Test y shape): {y_test.shape}\")\n",
    "\n",
    "    # Handle error if the target column is missing\n",
    "    except KeyError as e:\n",
    "        print(f\"âŒ ë°ì´í„° ë¶„í•  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    # Handle any other unexpected errors during splitting\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„° ë¶„í•  ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Unexpected error during data split): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWrEEXb3USRx",
    "outputId": "58184fdd-d432-4431-919a-0e8ac43d60d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ (Starting Hyperparameter Tuning - RandomizedSearchCV for RandomForest) ---\n",
      "5ê°œ ì¡°í•©, 2-ê²¹ êµì°¨ ê²€ì¦ìœ¼ë¡œ Randomized Search ì‹¤í–‰... (Running Randomized Search with 5 combinations and 2-fold CV...)\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "# ## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Hyperparameter Tuning)\n",
    "\n",
    "# RandomizedSearchCVë¥¼ ì‚¬ìš©í•˜ì—¬ Random Forest ëª¨ë¸ì˜ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
    "# Use RandomizedSearchCV to find the optimal combination of hyperparameters for the Random Forest model.\n",
    "best_params_rf = None # Initialize variable to store best parameters\n",
    "# Proceed only if training data is available\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(\"\\n--- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ (Starting Hyperparameter Tuning - RandomizedSearchCV for RandomForest) ---\")\n",
    "    # Initialize the Random Forest Regressor model for tuning\n",
    "    # random_state for reproducibility, n_jobs=-1 to use all CPU cores\n",
    "    rf_model_tune = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Define the parameter space (distributions) to sample from during Randomized Search\n",
    "    param_dist_rf = {\n",
    "        'n_estimators': np.arange(50, 501, 50),     # Number of trees: 50, 100, ..., 500\n",
    "        'max_depth': [None] + list(np.arange(5, 31, 5)), # Max depth: None (unlimited), 5, 10, ..., 30\n",
    "        'min_samples_split': [2, 5, 10, 15],         # Min samples to split a node: 2, 5, 10, 15\n",
    "        'min_samples_leaf': [1, 3, 5, 7],            # Min samples at a leaf node: 1, 3, 5, 7\n",
    "        'max_features': ['sqrt', 'log2', 0.5, 0.7] # Max features for split: sqrt(n_features), log2(n_features), 50%, 70%\n",
    "        # 'bootstrap': [True, False] # Whether bootstrap samples are used (optional)\n",
    "    }\n",
    "\n",
    "    # Configure RandomizedSearchCV\n",
    "    # n_iter: Number of parameter settings that are sampled. Trades off runtime vs quality of the solution.\n",
    "    # cv: Number of cross-validation folds.\n",
    "    # scoring: Strategy to evaluate the performance of the cross-validated model on the test set. 'neg_mean_squared_error' is common for regression.\n",
    "    # verbose: Controls the verbosity: the higher, the more messages.\n",
    "    # n_jobs=-1: Use all available CPU cores for parallel processing.\n",
    "    n_iterations = 5 # Number of iterations (parameter combinations to try). Adjust based on available time.\n",
    "    cv_folds = 2      # Number of cross-validation folds. Adjust based on available time/data size.\n",
    "\n",
    "    random_search_rf = RandomizedSearchCV(\n",
    "        estimator=rf_model_tune,           # The model to tune\n",
    "        param_distributions=param_dist_rf, # The distributions to sample parameters from\n",
    "        n_iter=n_iterations,               # Number of parameter settings that are sampled\n",
    "        scoring='neg_mean_squared_error',  # Metric to evaluate the performance (negative MSE)\n",
    "        cv=cv_folds,                       # Number of cross-validation folds\n",
    "        verbose=1,                         # Print progress messages\n",
    "        random_state=42,                   # Seed for reproducibility\n",
    "        n_jobs=-1                          # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Randomized Search ì‹¤í–‰ (Execute Randomized Search on the training data)\n",
    "    try:\n",
    "        print(f\"{n_iterations}ê°œ ì¡°í•©, {cv_folds}-ê²¹ êµì°¨ ê²€ì¦ìœ¼ë¡œ Randomized Search ì‹¤í–‰... (Running Randomized Search with {n_iterations} combinations and {cv_folds}-fold CV...)\")\n",
    "        # Fit RandomizedSearchCV to find the best parameters\n",
    "        random_search_rf.fit(X_train, y_train)\n",
    "        # Store the best parameters found\n",
    "        best_params_rf = random_search_rf.best_params_\n",
    "        print(\"\\nâœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ (Hyperparameter tuning complete)\")\n",
    "        print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° (Best hyperparameters - Random Forest):\", best_params_rf)\n",
    "        # The best_score_ attribute gives the score for the best parameters found.\n",
    "        # Since scoring='neg_mean_squared_error', a higher score (closer to 0) is better.\n",
    "        print(f\"ìµœê³  êµì°¨ ê²€ì¦ ì ìˆ˜ (Best cross-validation score - Negative MSE): {random_search_rf.best_score_:.6f}\")\n",
    "    # Handle potential errors during the tuning process\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error during hyperparameter tuning): {e}\")\n",
    "        best_params_rf = None # Reset best parameters on error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7RyfN5ZgD-wo"
   },
   "outputs": [],
   "source": [
    " ## ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (Final Model Training & Evaluation)\n",
    "\n",
    "# RandomizedSearchCVë¥¼ í†µí•´ ì°¾ì€ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… Random Forest ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "# Train the final Random Forest model using the best hyperparameters found by RandomizedSearchCV and evaluate its performance on the test data.\n",
    "rf_final_model = None # Initialize final model variable to None\n",
    "# Proceed only if best parameters were found and training data exists\n",
    "if best_params_rf is not None and X_train is not None and y_train is not None:\n",
    "    print(\"\\n--- ìµœì  íŒŒë¼ë¯¸í„°ë¡œ Random Forest ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì‹œì‘ (Starting final Random Forest model training and evaluation with best parameters) ---\")\n",
    "    # Initialize the final model using the best parameters found\n",
    "    # The ** operator unpacks the dictionary into keyword arguments\n",
    "    rf_final_model = RandomForestRegressor(\n",
    "        **best_params_rf,\n",
    "        random_state=42, # Ensure reproducibility for the final model\n",
    "        n_jobs=-1        # Use all CPU cores\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ (Train the final model on the entire training dataset)\n",
    "    try:\n",
    "        print(\"ìµœì  ëª¨ë¸ í•™ìŠµ ì¤‘... (Training the optimal model...)\")\n",
    "        # Fit the model\n",
    "        rf_final_model.fit(X_train, y_train)\n",
    "        print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (Model training complete)\")\n",
    "\n",
    "        # ì˜ˆì¸¡ ìˆ˜í–‰ (Make predictions on both training and test data)\n",
    "        print(\"ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘... (Making predictions...)\")\n",
    "        y_train_pred_rf = rf_final_model.predict(X_train) # Predictions on training data\n",
    "        y_test_pred_rf = rf_final_model.predict(X_test)   # Predictions on test data\n",
    "        print(\"âœ… ì˜ˆì¸¡ ìˆ˜í–‰ ì™„ë£Œ (Prediction complete)\")\n",
    "\n",
    "        # í‰ê°€ ì§€í‘œ ê³„ì‚° (Calculate various evaluation metrics)\n",
    "        print(\"í‰ê°€ ì§€í‘œ ê³„ì‚° ì¤‘... (Calculating evaluation metrics...)\")\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "        test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "        # Mean Squared Error (MSE)\n",
    "        train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "        test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "        # Mean Absolute Error (MAE)\n",
    "        train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "        test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        train_rmse_rf = np.sqrt(train_mse_rf)\n",
    "        test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "\n",
    "        # MAPE ê³„ì‚° í•¨ìˆ˜ ì •ì˜ (Define MAPE function to handle potential division by zero)\n",
    "        def mean_absolute_percentage_error(y_true, y_pred):\n",
    "            # Convert inputs to numpy arrays\n",
    "            y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "            # Create a mask for non-zero true values to avoid division by zero\n",
    "            non_zero_mask = y_true != 0\n",
    "            # If all true values are zero, return NaN\n",
    "            if np.sum(non_zero_mask) == 0: return np.nan\n",
    "            # Calculate MAPE only for non-zero true values and take the mean\n",
    "            return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "        # Calculate Mean Absolute Percentage Error (MAPE)\n",
    "        train_mape_rf = mean_absolute_percentage_error(y_train, y_train_pred_rf)\n",
    "        test_mape_rf = mean_absolute_percentage_error(y_test, y_test_pred_rf)\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥ (Print the calculated evaluation metrics)\n",
    "        print(\"\\n--- Random Forest ëª¨ë¸ í‰ê°€ ê²°ê³¼ (íŠœë‹ í›„) (Random Forest Model Evaluation Results - Tuned) ---\")\n",
    "        print(f\"Train R2: {train_r2_rf:.6f}\")\n",
    "        print(f\"Test R2 : {test_r2_rf:.6f}\")\n",
    "        print(f\"Train MSE: {train_mse_rf:.6f}\")\n",
    "        print(f\"Test MSE : {test_mse_rf:.6f}\")\n",
    "        print(f\"Train MAE: {train_mae_rf:.6f}\")\n",
    "        print(f\"Test MAE : {test_mae_rf:.6f}\")\n",
    "        print(f\"Train RMSE: {train_rmse_rf:.6f}\")\n",
    "        print(f\"Test RMSE : {test_rmse_rf:.6f}\")\n",
    "        # Check if MAPE is NaN before formatting\n",
    "        train_mape_str = f\"{train_mape_rf:.4f}%\" if not np.isnan(train_mape_rf) else \"N/A (y_train contains zeros)\"\n",
    "        test_mape_str = f\"{test_mape_rf:.4f}%\" if not np.isnan(test_mape_rf) else \"N/A (y_test contains zeros)\"\n",
    "        print(f\"Train MAPE: {train_mape_str}\")\n",
    "        print(f\"Test MAPE : {test_mape_str}\")\n",
    "\n",
    "    # Handle potential errors during final model training or evaluation\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ í•™ìŠµ ë˜ëŠ” í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error during model training or evaluation): {e}\")\n",
    "        rf_final_model = None # Reset final model variable on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GMGpL-s2ECSU"
   },
   "outputs": [],
   "source": [
    "# ## íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (Feature Importance Analysis)\n",
    "\n",
    "# í•™ìŠµëœ ìµœì¢… Random Forest ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ í™•ì¸í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "# Check and visualize the feature importances of the trained final Random Forest model.\n",
    "# Proceed only if the final model was trained successfully and training data exists\n",
    "if rf_final_model is not None and X_train is not None:\n",
    "    print(\"\\n--- Random Forest íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸ (Checking Random Forest Feature Importances) ---\")\n",
    "    try:\n",
    "        # Extract feature importances from the trained model\n",
    "        importances_rf = rf_final_model.feature_importances_\n",
    "        # Get the names of the features\n",
    "        feature_names_rf = X_train.columns\n",
    "        # Create a DataFrame for easier handling and sorting\n",
    "        feature_importance_df_rf = pd.DataFrame({'feature': feature_names_rf, 'importance': importances_rf})\n",
    "        # Sort features by importance in descending order\n",
    "        feature_importance_df_rf = feature_importance_df_rf.sort_values(by='importance', ascending=False)\n",
    "\n",
    "        # Print the top 10 most important features\n",
    "        print(\"ìƒìœ„ 10ê°œ íŠ¹ì„± ì¤‘ìš”ë„ (Top 10 Feature Importances - Random Forest):\")\n",
    "        print(feature_importance_df_rf.head(10))\n",
    "\n",
    "        # íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” (Visualize feature importances - Top 10)\n",
    "        plt.figure(figsize=(12, 7)) # Adjust figure size for better readability\n",
    "        top_n = 10\n",
    "        # Select top N features and sort them ascending for plotting (makes highest importance appear at the top)\n",
    "        top_features_rf = feature_importance_df_rf.head(top_n).sort_values(by='importance', ascending=True)\n",
    "\n",
    "        # Create horizontal bar plot using seaborn for potentially better aesthetics\n",
    "        sns.barplot(x='importance', y='feature', data=top_features_rf, palette='viridis') # Use a color palette\n",
    "        # plt.barh(top_features_rf['feature'], top_features_rf['importance'], color='skyblue') # Alternative using Matplotlib\n",
    "\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title(f'Top {top_n} Feature Importances (Random Forest - Tuned)')\n",
    "        plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "        plt.show() # Display the plot\n",
    "\n",
    "\n",
    "    # Handle potential errors during importance calculation or visualization\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸ ë˜ëŠ” ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error during feature importance check or visualization): {e}\")\n",
    "\n",
    "# Indicate the end of the notebook execution\n",
    "print(\"\\n--- ëª¨ë“  ì‘ì—… ì™„ë£Œ (All tasks completed) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3da4acd7"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í‰ê°€ (Model Evaluation)\n",
    "if best_params_rf is not None and X_test is not None and y_test is not None:\n",
    "    print(\"\\n--- ëª¨ë¸ í‰ê°€ ì‹œì‘ (Starting Model Evaluation) ---\")\n",
    "    try:\n",
    "        # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ (Train final model with best parameters)\n",
    "        final_rf_model = RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1)\n",
    "        final_rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ (Predict on test data)\n",
    "        y_pred = final_rf_model.predict(X_test)\n",
    "\n",
    "        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (Calculate performance metrics)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse) # RMSE\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(\"\\nâœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ (Model evaluation complete)!\")\n",
    "        print(f\"âœ¨ Mean Squared Error (MSE): {mse:.4f}\")\n",
    "        print(f\"âœ¨ Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "        print(f\"âœ¨ Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "        print(f\"âœ¨ R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Error during model evaluation): {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMgBRcPBjTVWgwa2rv6eHDK",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
