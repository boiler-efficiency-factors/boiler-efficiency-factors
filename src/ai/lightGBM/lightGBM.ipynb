{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd002ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" libarary & init \"\"\"\n",
    "\n",
    "# libararies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ac942",
   "metadata": {},
   "source": [
    "## 데이터 로드 및 EDA 수행\n",
    "- branch : feat/7-dataload-eda\n",
    "- tasks\n",
    "    - 결측치 및 이상치 확인\n",
    "    - 데이터 기본 통계량 확인\n",
    "    - 타켓 변수 정의 (효율 계산식에 따른 타켓 변수)\n",
    "    - 각 피처별 분포 시각화 (히스토그램)\n",
    "    - 주요 인자들과 보일러 효율 간의 관계 시각화\n",
    "    - 인자들 간의 상관관계 분석 (히트맵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d62bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 '2025-01-01'부터 '2025-06-30'까지의 데이터를 로드합니다...\n",
      "  - 로드 성공: 28_2025-01-01.csv\n",
      "  - 로드 성공: 28_2025-01-02.csv\n",
      "  - 로드 성공: 28_2025-01-03.csv\n",
      "  - 로드 성공: 28_2025-01-04.csv\n",
      "  - 로드 성공: 28_2025-01-05.csv\n",
      "  - 로드 성공: 28_2025-01-06.csv\n",
      "  - 로드 성공: 28_2025-01-07.csv\n",
      "  - 로드 성공: 28_2025-01-08.csv\n",
      "  - 로드 성공: 28_2025-01-09.csv\n",
      "  - 로드 성공: 28_2025-01-10.csv\n",
      "  - 로드 성공: 28_2025-01-11.csv\n",
      "  - 로드 성공: 28_2025-01-12.csv\n",
      "  - 로드 성공: 28_2025-01-13.csv\n",
      "  - 로드 성공: 28_2025-01-14.csv\n",
      "  - 로드 성공: 28_2025-01-15.csv\n",
      "  - 로드 성공: 28_2025-01-16.csv\n",
      "  - 로드 성공: 28_2025-01-17.csv\n",
      "  - 로드 성공: 28_2025-01-18.csv\n",
      "  - 로드 성공: 28_2025-01-19.csv\n",
      "  - 로드 성공: 28_2025-01-20.csv\n",
      "  - 로드 성공: 28_2025-01-21.csv\n",
      "  - 로드 성공: 28_2025-01-22.csv\n",
      "  - 로드 성공: 28_2025-01-23.csv\n",
      "  - 로드 성공: 28_2025-01-24.csv\n",
      "  - 로드 성공: 28_2025-01-25.csv\n",
      "  - 로드 성공: 28_2025-01-26.csv\n",
      "  - 로드 성공: 28_2025-01-27.csv\n",
      "  - 로드 성공: 28_2025-01-28.csv\n",
      "  - 로드 성공: 28_2025-01-29.csv\n",
      "  - 로드 성공: 28_2025-01-30.csv\n",
      "  - 로드 성공: 28_2025-01-31.csv\n",
      "  - 로드 성공: 28_2025-02-01.csv\n",
      "  - 로드 성공: 28_2025-02-02.csv\n",
      "  - 로드 성공: 28_2025-02-03.csv\n",
      "  - 로드 성공: 28_2025-02-04.csv\n",
      "  - 로드 성공: 28_2025-02-05.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeyu\\AppData\\Local\\Temp\\ipykernel_40860\\953213486.py:26: DtypeWarning: Columns (19,20,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(file_path, encoding='cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 로드 성공: 28_2025-02-06.csv\n",
      "  - 로드 성공: 28_2025-02-07.csv\n",
      "  - 로드 성공: 28_2025-02-08.csv\n",
      "  - 로드 성공: 28_2025-02-09.csv\n",
      "  - 로드 성공: 28_2025-02-10.csv\n",
      "  - 로드 성공: 28_2025-02-11.csv\n",
      "  - 로드 성공: 28_2025-02-12.csv\n",
      "  - 로드 성공: 28_2025-02-13.csv\n",
      "  - 로드 성공: 28_2025-02-14.csv\n",
      "  - 로드 성공: 28_2025-02-15.csv\n",
      "  - 로드 성공: 28_2025-02-16.csv\n",
      "  - 로드 성공: 28_2025-02-17.csv\n",
      "  - 로드 성공: 28_2025-02-18.csv\n",
      "  - 로드 성공: 28_2025-02-19.csv\n",
      "  - 로드 성공: 28_2025-02-20.csv\n",
      "  - 로드 성공: 28_2025-02-21.csv\n",
      "  - 로드 성공: 28_2025-02-22.csv\n",
      "  - 로드 성공: 28_2025-02-23.csv\n",
      "  - 로드 성공: 28_2025-02-24.csv\n",
      "  - 로드 성공: 28_2025-02-25.csv\n",
      "  - 로드 성공: 28_2025-02-26.csv\n",
      "  - 로드 성공: 28_2025-02-27.csv\n",
      "  - 로드 성공: 28_2025-02-28.csv\n",
      "  - 로드 성공: 28_2025-03-01.csv\n",
      "  - 로드 성공: 28_2025-03-02.csv\n",
      "  - 로드 성공: 28_2025-03-03.csv\n",
      "  - 로드 성공: 28_2025-03-04.csv\n",
      "  - 로드 성공: 28_2025-03-05.csv\n",
      "  - 로드 성공: 28_2025-03-06.csv\n",
      "  - 로드 성공: 28_2025-03-07.csv\n",
      "  - 로드 성공: 28_2025-03-08.csv\n",
      "  - 로드 성공: 28_2025-03-09.csv\n",
      "  - 로드 성공: 28_2025-03-10.csv\n",
      "  - 로드 성공: 28_2025-03-11.csv\n",
      "  - 로드 성공: 28_2025-03-12.csv\n",
      "  - 로드 성공: 28_2025-03-13.csv\n",
      "  - 로드 성공: 28_2025-03-14.csv\n",
      "  - 로드 성공: 28_2025-03-15.csv\n",
      "  - 로드 성공: 28_2025-03-16.csv\n",
      "  - 로드 성공: 28_2025-03-17.csv\n",
      "  - 로드 성공: 28_2025-03-18.csv\n",
      "  - 로드 성공: 28_2025-03-19.csv\n",
      "  - 로드 성공: 28_2025-03-20.csv\n",
      "  - 로드 성공: 28_2025-03-21.csv\n",
      "  - 로드 성공: 28_2025-03-22.csv\n",
      "  - 로드 성공: 28_2025-03-23.csv\n",
      "  - 로드 성공: 28_2025-03-24.csv\n",
      "  - 로드 성공: 28_2025-03-25.csv\n",
      "  - 로드 성공: 28_2025-03-26.csv\n",
      "  - 로드 성공: 28_2025-03-27.csv\n",
      "  - 로드 성공: 28_2025-03-28.csv\n",
      "  - 로드 성공: 28_2025-03-29.csv\n",
      "  - 로드 성공: 28_2025-03-30.csv\n",
      "  - 로드 성공: 28_2025-03-31.csv\n",
      "  - 로드 성공: 28_2025-04-01.csv\n",
      "  - 로드 성공: 28_2025-04-02.csv\n",
      "  - 로드 성공: 28_2025-04-03.csv\n",
      "  - 로드 성공: 28_2025-04-04.csv\n",
      "  - 로드 성공: 28_2025-04-05.csv\n",
      "  - 로드 성공: 28_2025-04-06.csv\n",
      "  - 로드 성공: 28_2025-04-07.csv\n",
      "  - 로드 성공: 28_2025-04-08.csv\n",
      "  - 로드 성공: 28_2025-04-09.csv\n",
      "  - 로드 성공: 28_2025-04-10.csv\n",
      "  - 로드 성공: 28_2025-04-11.csv\n",
      "  - 로드 성공: 28_2025-04-12.csv\n",
      "  - 로드 성공: 28_2025-04-13.csv\n",
      "  - 로드 성공: 28_2025-04-14.csv\n",
      "  - 로드 성공: 28_2025-04-15.csv\n",
      "  - 로드 성공: 28_2025-04-16.csv\n",
      "  - 로드 성공: 28_2025-04-17.csv\n",
      "  - 로드 성공: 28_2025-04-18.csv\n",
      "  - 로드 성공: 28_2025-04-19.csv\n",
      "  - 로드 성공: 28_2025-04-20.csv\n",
      "  - 로드 성공: 28_2025-04-21.csv\n",
      "  - 로드 성공: 28_2025-04-22.csv\n",
      "  - 로드 성공: 28_2025-04-23.csv\n",
      "  - 로드 성공: 28_2025-04-24.csv\n",
      "  - 로드 성공: 28_2025-04-25.csv\n",
      "  - 로드 성공: 28_2025-04-26.csv\n",
      "  - 로드 성공: 28_2025-04-27.csv\n",
      "  - 로드 성공: 28_2025-04-28.csv\n",
      "  - 로드 성공: 28_2025-04-29.csv\n",
      "  - 로드 성공: 28_2025-04-30.csv\n",
      "  - 로드 성공: 28_2025-05-01.csv\n",
      "  - 로드 성공: 28_2025-05-02.csv\n",
      "  - 로드 성공: 28_2025-05-03.csv\n",
      "  - 로드 성공: 28_2025-05-04.csv\n",
      "  - 로드 성공: 28_2025-05-05.csv\n",
      "  - 로드 성공: 28_2025-05-06.csv\n",
      "  - 로드 성공: 28_2025-05-07.csv\n",
      "  - 로드 성공: 28_2025-05-08.csv\n",
      "  - 로드 성공: 28_2025-05-09.csv\n",
      "  - 로드 성공: 28_2025-05-10.csv\n",
      "  - 로드 성공: 28_2025-05-11.csv\n",
      "  - 로드 성공: 28_2025-05-12.csv\n",
      "  - 로드 성공: 28_2025-05-13.csv\n",
      "  - 로드 성공: 28_2025-05-14.csv\n",
      "  - 로드 성공: 28_2025-05-15.csv\n",
      "  - 로드 성공: 28_2025-05-16.csv\n",
      "  - 로드 성공: 28_2025-05-17.csv\n",
      "  - 로드 성공: 28_2025-05-18.csv\n",
      "  - 로드 성공: 28_2025-05-19.csv\n",
      "  - 로드 성공: 28_2025-05-20.csv\n",
      "  - 로드 성공: 28_2025-05-21.csv\n",
      "  - 로드 성공: 28_2025-05-22.csv\n",
      "  - 로드 성공: 28_2025-05-23.csv\n",
      "  - 로드 성공: 28_2025-05-24.csv\n",
      "  - 로드 성공: 28_2025-05-25.csv\n",
      "  - 로드 성공: 28_2025-05-26.csv\n",
      "  - 로드 성공: 28_2025-05-27.csv\n",
      "  - 로드 성공: 28_2025-05-28.csv\n",
      "  - 로드 성공: 28_2025-05-29.csv\n",
      "  - 로드 성공: 28_2025-05-30.csv\n",
      "  - 로드 성공: 28_2025-05-31.csv\n",
      "  - 로드 성공: 28_2025-06-01.csv\n",
      "  - 로드 성공: 28_2025-06-02.csv\n",
      "  - 로드 성공: 28_2025-06-03.csv\n",
      "  - 로드 성공: 28_2025-06-04.csv\n",
      "  - 로드 성공: 28_2025-06-05.csv\n",
      "  - 로드 성공: 28_2025-06-06.csv\n",
      "  - 로드 성공: 28_2025-06-07.csv\n",
      "  - 로드 성공: 28_2025-06-08.csv\n",
      "  - 로드 성공: 28_2025-06-09.csv\n",
      "  - 로드 성공: 28_2025-06-10.csv\n",
      "  - 로드 성공: 28_2025-06-11.csv\n",
      "  - 로드 성공: 28_2025-06-12.csv\n",
      "  - 로드 성공: 28_2025-06-13.csv\n",
      "  - 로드 성공: 28_2025-06-14.csv\n",
      "  - 로드 성공: 28_2025-06-15.csv\n",
      "  - 로드 성공: 28_2025-06-16.csv\n",
      "  - 로드 성공: 28_2025-06-17.csv\n",
      "  - 로드 성공: 28_2025-06-18.csv\n",
      "  - 로드 성공: 28_2025-06-19.csv\n",
      "  - 로드 성공: 28_2025-06-20.csv\n",
      "  - 로드 성공: 28_2025-06-21.csv\n",
      "  - 로드 성공: 28_2025-06-22.csv\n",
      "  - 로드 성공: 28_2025-06-23.csv\n",
      "  - 로드 성공: 28_2025-06-24.csv\n",
      "  - 로드 성공: 28_2025-06-25.csv\n",
      "  - 로드 성공: 28_2025-06-26.csv\n",
      "  - 로드 성공: 28_2025-06-27.csv\n",
      "  - 로드 성공: 28_2025-06-28.csv\n",
      "  - 로드 성공: 28_2025-06-29.csv\n",
      "  - 로드 성공: 28_2025-06-30.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeyu\\AppData\\Local\\Temp\\ipykernel_40860\\953213486.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(dfs_to_concat, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 총 181개 파일, 6143352개 행의 데이터를 성공적으로 합쳤습니다.\n",
      "\n",
      "--- [결과] 로드된 데이터 확인 (상위 5개) ---\n",
      "   ??????  ??????.1  ???? ???  ????? ???  ????? ????? ???  ????? ???.1  \\\n",
      "0    60.0       5.6       5.4       69.0             59.2          0.0   \n",
      "1    60.0       5.6       5.4       69.0             59.3          0.0   \n",
      "2    60.0       5.6       5.4       69.0             59.2          0.0   \n",
      "3    60.0       5.6       5.4       69.0             59.3         75.0   \n",
      "4    60.0       5.6       5.4       69.0             59.2         75.0   \n",
      "\n",
      "   ??? ????  ??????? ???  ???? ????  ???? ???? ???  ...  운전시간  정상 운전 확률  \\\n",
      "0       0.0         30.0       30.5           35.0  ...   NaN       NaN   \n",
      "1       0.0         30.0       30.8           35.0  ...   NaN       NaN   \n",
      "2       0.0         30.0       30.8           35.0  ...   NaN       NaN   \n",
      "3       0.0         30.0       30.8           35.0  ...   NaN       NaN   \n",
      "4       0.0         30.0       30.6           35.0  ...   NaN       NaN   \n",
      "\n",
      "   송풍기 고장 확률  AIR 댐퍼 고장 확률  GAS 앰퍼 고장 확률  확률 업데이트 시간  순간 스팀량  입출력법 효율  \\\n",
      "0        NaN           NaN           NaN         NaN     NaN      NaN   \n",
      "1        NaN           NaN           NaN         NaN     NaN      NaN   \n",
      "2        NaN           NaN           NaN         NaN     NaN      NaN   \n",
      "3        NaN           NaN           NaN         NaN     NaN      NaN   \n",
      "4        NaN           NaN           NaN         NaN     NaN      NaN   \n",
      "\n",
      "   열 손실법 효율  효율(입출력법-스팀)  \n",
      "0       NaN          NaN  \n",
      "1       NaN          NaN  \n",
      "2       NaN          NaN  \n",
      "3       NaN          NaN  \n",
      "4       NaN          NaN  \n",
      "\n",
      "[5 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" path settings & dataload \"\"\"\n",
    "\n",
    "def load_data(start_date, end_date):\n",
    "    # 데이터 경로 설정\n",
    "    data_path = '../data/rowdata-2025'\n",
    "    data_dir = Path(data_path)\n",
    "\n",
    "    # 시작일부터 종료일까지의 모든 날짜 생성\n",
    "    dates_to_load = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    # 각 날짜에 해당하는 csv 파일 리스트\n",
    "    dfs_to_concat = []\n",
    "    \n",
    "    print(f\"🔍 '{start_date}'부터 '{end_date}'까지의 데이터를 로드합니다...\")\n",
    "    \n",
    "    # 각 날짜를 순회하며 파일 로드\n",
    "    for date in dates_to_load:\n",
    "        # 파일 이름 형식에 맞게 문자열 포맷팅 (예: 28_2025-01-05.csv)\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        filename = f\"28_{date_str}.csv\"\n",
    "        file_path = data_dir / filename\n",
    "        \n",
    "        # 5. 파일이 실제로 존재하는지 확인 후 로드\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                temp_df = pd.read_csv(file_path, encoding='cp949')\n",
    "                dfs_to_concat.append(temp_df)\n",
    "                print(f\"  - 로드 성공: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  - ❌ 로드 실패: {filename} (에러: {e})\")\n",
    "        else:\n",
    "            print(f\"  - 파일 없음: {filename}\")\n",
    "            \n",
    "    # 로드된 모든 데이터프레임을 하나로 합치기\n",
    "    if dfs_to_concat:\n",
    "        # ignore_index=True: 각 파일의 기존 인덱스를 무시하고 새로 인덱스를 부여 (0, 1, 2, ...)\n",
    "        combined_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "        print(f\"\\n✅ 총 {len(dfs_to_concat)}개 파일, {len(combined_df)}개 행의 데이터를 성공적으로 합쳤습니다.\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"\\n❌ 해당 기간에 로드할 데이터 파일이 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "start_date_input = '2025-01-01'\n",
    "end_date_input = '2025-06-30'\n",
    "\n",
    "rowdata_df = load_data(start_date=start_date_input, end_date=end_date_input)\n",
    "\n",
    "if rowdata_df is not None:\n",
    "    print(\"\\n--- [결과] 로드된 데이터 확인 (상위 5개) ---\")\n",
    "    print(rowdata_df.head())\n",
    "else:\n",
    "    print(\"\\n--- [결과] 최종 데이터프레임이 비어있어 출력할 내용이 없습니다. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00487bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " ??????             6093381\n",
      "??????.1           6093381\n",
      "???? ???           6093381\n",
      "????? ???          6093381\n",
      "????? ????? ???    6093381\n",
      "                    ...   \n",
      "확률 업데이트 시간           49971\n",
      "순간 스팀량               49971\n",
      "입출력법 효율              49972\n",
      "열 손실법 효율             49971\n",
      "효율(입출력법-스팀)        6143352\n",
      "Length: 94, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leeyu\\anaconda3\\envs\\ai-env\\lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['???(??????-????)' '효율(입출력법-스팀)']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (6143352, 80), indices imply (6143352, 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m num_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m rowdata_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m imputed_numeric_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_cols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_cols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m rowdata_df[numeric_cols\u001b[38;5;241m.\u001b[39mcolumns] \u001b[38;5;241m=\u001b[39m imputed_numeric_data\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter handling missing values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, rowdata_df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\leeyu\\anaconda3\\envs\\ai-env\\lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\leeyu\\anaconda3\\envs\\ai-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\leeyu\\anaconda3\\envs\\ai-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (6143352, 80), indices imply (6143352, 82)"
     ]
    }
   ],
   "source": [
    "\"\"\" 결측치 및 이상치 확인 \"\"\"\n",
    "\n",
    "# 데이터 진단 : 결측치 확인(Check for missing values)\n",
    "print(\"Missing values per column:\\n\", rowdata_df.isnull().sum())\n",
    "\n",
    "# 결측치 핸들링\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "numeric_cols = rowdata_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "imputed_numeric_data = pd.DataFrame(\n",
    "    num_imputer.fit_transform(numeric_cols),\n",
    "    columns=numeric_cols.columns,\n",
    "    index=numeric_cols.index\n",
    ")\n",
    "\n",
    "rowdata_df[numeric_cols.columns] = imputed_numeric_data\n",
    "\n",
    "print(\"After handling missing values:\\n\", rowdata_df.isnull().sum())\n",
    "\n",
    "index_array = rowdata_df.index.values\n",
    "print(\"\\nPreserved index:\\n\", index_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
